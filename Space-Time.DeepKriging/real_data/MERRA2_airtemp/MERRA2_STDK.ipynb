{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edfb331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs: []\n",
      "[FILES] using last: 5\n",
      "first: M2T1NXFLX.5.12.4%3AMERRA2_400.tavg1_2d_flx_Nx.20241227.nc4.dap.nc4\n",
      "last : M2T1NXFLX.5.12.4%3AMERRA2_400.tavg1_2d_flx_Nx.20241231.nc4.dap.nc4\n",
      "Y (S,T_KEEP): (207936, 100)\n",
      "t_last range: 2024-12-27T20:30:00.000000000 -> 2024-12-31T23:30:00.000000000\n",
      "Ds: 250 Dt: 70 D: 320\n",
      "Stations: train 18715 | val 2079 | miss 187142\n",
      "train rows: 1871500 | val rows: 207900\n",
      "steps/epoch: 3656 | val_steps: 407\n",
      "Epoch 1/300\n",
      "3656/3656 [==============================] - 21s 5ms/step - loss: 0.5202 - q0_05_loss: 0.0513 - q0_25_loss: 0.1527 - q0_5_loss: 0.1599 - q0_75_loss: 0.1069 - q0_95_loss: 0.0345 - val_loss: 0.2740 - val_q0_05_loss: 0.0213 - val_q0_25_loss: 0.0671 - val_q0_5_loss: 0.0842 - val_q0_75_loss: 0.0640 - val_q0_95_loss: 0.0212\n",
      "Epoch 2/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.2250 - q0_05_loss: 0.0209 - q0_25_loss: 0.0526 - q0_5_loss: 0.0635 - q0_75_loss: 0.0514 - q0_95_loss: 0.0197 - val_loss: 0.2160 - val_q0_05_loss: 0.0210 - val_q0_25_loss: 0.0547 - val_q0_5_loss: 0.0585 - val_q0_75_loss: 0.0473 - val_q0_95_loss: 0.0174\n",
      "Epoch 3/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.2107 - q0_05_loss: 0.0197 - q0_25_loss: 0.0487 - q0_5_loss: 0.0587 - q0_75_loss: 0.0479 - q0_95_loss: 0.0185 - val_loss: 0.1929 - val_q0_05_loss: 0.0181 - val_q0_25_loss: 0.0445 - val_q0_5_loss: 0.0523 - val_q0_75_loss: 0.0433 - val_q0_95_loss: 0.0175\n",
      "Epoch 4/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.2004 - q0_05_loss: 0.0189 - q0_25_loss: 0.0464 - q0_5_loss: 0.0554 - q0_75_loss: 0.0451 - q0_95_loss: 0.0176 - val_loss: 0.2004 - val_q0_05_loss: 0.0178 - val_q0_25_loss: 0.0427 - val_q0_5_loss: 0.0567 - val_q0_75_loss: 0.0487 - val_q0_95_loss: 0.0175\n",
      "Epoch 5/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1946 - q0_05_loss: 0.0186 - q0_25_loss: 0.0451 - q0_5_loss: 0.0536 - q0_75_loss: 0.0435 - q0_95_loss: 0.0169 - val_loss: 0.1942 - val_q0_05_loss: 0.0173 - val_q0_25_loss: 0.0426 - val_q0_5_loss: 0.0549 - val_q0_75_loss: 0.0448 - val_q0_95_loss: 0.0178\n",
      "Epoch 6/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1905 - q0_05_loss: 0.0181 - q0_25_loss: 0.0440 - q0_5_loss: 0.0524 - q0_75_loss: 0.0425 - q0_95_loss: 0.0166 - val_loss: 0.2061 - val_q0_05_loss: 0.0216 - val_q0_25_loss: 0.0519 - val_q0_5_loss: 0.0562 - val_q0_75_loss: 0.0428 - val_q0_95_loss: 0.0167\n",
      "Epoch 7/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1876 - q0_05_loss: 0.0180 - q0_25_loss: 0.0434 - q0_5_loss: 0.0513 - q0_75_loss: 0.0417 - q0_95_loss: 0.0164 - val_loss: 0.1934 - val_q0_05_loss: 0.0190 - val_q0_25_loss: 0.0456 - val_q0_5_loss: 0.0522 - val_q0_75_loss: 0.0439 - val_q0_95_loss: 0.0159\n",
      "Epoch 8/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1854 - q0_05_loss: 0.0178 - q0_25_loss: 0.0427 - q0_5_loss: 0.0506 - q0_75_loss: 0.0412 - q0_95_loss: 0.0162 - val_loss: 0.1796 - val_q0_05_loss: 0.0177 - val_q0_25_loss: 0.0412 - val_q0_5_loss: 0.0480 - val_q0_75_loss: 0.0404 - val_q0_95_loss: 0.0155\n",
      "Epoch 9/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1820 - q0_05_loss: 0.0175 - q0_25_loss: 0.0417 - q0_5_loss: 0.0495 - q0_75_loss: 0.0404 - q0_95_loss: 0.0160 - val_loss: 0.1857 - val_q0_05_loss: 0.0181 - val_q0_25_loss: 0.0437 - val_q0_5_loss: 0.0511 - val_q0_75_loss: 0.0404 - val_q0_95_loss: 0.0155\n",
      "Epoch 10/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1808 - q0_05_loss: 0.0174 - q0_25_loss: 0.0415 - q0_5_loss: 0.0491 - q0_75_loss: 0.0401 - q0_95_loss: 0.0157 - val_loss: 0.1858 - val_q0_05_loss: 0.0183 - val_q0_25_loss: 0.0446 - val_q0_5_loss: 0.0502 - val_q0_75_loss: 0.0405 - val_q0_95_loss: 0.0151\n",
      "Epoch 11/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1794 - q0_05_loss: 0.0172 - q0_25_loss: 0.0409 - q0_5_loss: 0.0485 - q0_75_loss: 0.0398 - q0_95_loss: 0.0159 - val_loss: 0.1762 - val_q0_05_loss: 0.0170 - val_q0_25_loss: 0.0398 - val_q0_5_loss: 0.0477 - val_q0_75_loss: 0.0389 - val_q0_95_loss: 0.0157\n",
      "Epoch 12/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1787 - q0_05_loss: 0.0173 - q0_25_loss: 0.0408 - q0_5_loss: 0.0483 - q0_75_loss: 0.0394 - q0_95_loss: 0.0156 - val_loss: 0.1788 - val_q0_05_loss: 0.0173 - val_q0_25_loss: 0.0412 - val_q0_5_loss: 0.0477 - val_q0_75_loss: 0.0394 - val_q0_95_loss: 0.0159\n",
      "Epoch 13/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1770 - q0_05_loss: 0.0170 - q0_25_loss: 0.0402 - q0_5_loss: 0.0478 - q0_75_loss: 0.0392 - q0_95_loss: 0.0155 - val_loss: 0.1785 - val_q0_05_loss: 0.0175 - val_q0_25_loss: 0.0420 - val_q0_5_loss: 0.0481 - val_q0_75_loss: 0.0387 - val_q0_95_loss: 0.0149\n",
      "Epoch 14/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1760 - q0_05_loss: 0.0168 - q0_25_loss: 0.0400 - q0_5_loss: 0.0474 - q0_75_loss: 0.0389 - q0_95_loss: 0.0156 - val_loss: 0.1712 - val_q0_05_loss: 0.0171 - val_q0_25_loss: 0.0393 - val_q0_5_loss: 0.0455 - val_q0_75_loss: 0.0370 - val_q0_95_loss: 0.0148\n",
      "Epoch 15/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1756 - q0_05_loss: 0.0168 - q0_25_loss: 0.0399 - q0_5_loss: 0.0472 - q0_75_loss: 0.0388 - q0_95_loss: 0.0155 - val_loss: 0.1748 - val_q0_05_loss: 0.0179 - val_q0_25_loss: 0.0413 - val_q0_5_loss: 0.0471 - val_q0_75_loss: 0.0370 - val_q0_95_loss: 0.0141\n",
      "Epoch 16/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1740 - q0_05_loss: 0.0168 - q0_25_loss: 0.0395 - q0_5_loss: 0.0467 - q0_75_loss: 0.0382 - q0_95_loss: 0.0154 - val_loss: 0.2054 - val_q0_05_loss: 0.0182 - val_q0_25_loss: 0.0478 - val_q0_5_loss: 0.0589 - val_q0_75_loss: 0.0467 - val_q0_95_loss: 0.0162\n",
      "Epoch 17/300\n",
      "3656/3656 [==============================] - 19s 5ms/step - loss: 0.1735 - q0_05_loss: 0.0167 - q0_25_loss: 0.0394 - q0_5_loss: 0.0466 - q0_75_loss: 0.0381 - q0_95_loss: 0.0151 - val_loss: 0.1910 - val_q0_05_loss: 0.0169 - val_q0_25_loss: 0.0437 - val_q0_5_loss: 0.0540 - val_q0_75_loss: 0.0433 - val_q0_95_loss: 0.0155\n",
      "Epoch 18/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1735 - q0_05_loss: 0.0167 - q0_25_loss: 0.0393 - q0_5_loss: 0.0466 - q0_75_loss: 0.0382 - q0_95_loss: 0.0152 - val_loss: 0.1769 - val_q0_05_loss: 0.0174 - val_q0_25_loss: 0.0405 - val_q0_5_loss: 0.0480 - val_q0_75_loss: 0.0385 - val_q0_95_loss: 0.0150\n",
      "Epoch 19/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1720 - q0_05_loss: 0.0166 - q0_25_loss: 0.0390 - q0_5_loss: 0.0461 - q0_75_loss: 0.0377 - q0_95_loss: 0.0149 - val_loss: 0.1803 - val_q0_05_loss: 0.0188 - val_q0_25_loss: 0.0435 - val_q0_5_loss: 0.0473 - val_q0_75_loss: 0.0377 - val_q0_95_loss: 0.0155\n",
      "Epoch 20/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1708 - q0_05_loss: 0.0164 - q0_25_loss: 0.0386 - q0_5_loss: 0.0457 - q0_75_loss: 0.0375 - q0_95_loss: 0.0150 - val_loss: 0.1839 - val_q0_05_loss: 0.0212 - val_q0_25_loss: 0.0438 - val_q0_5_loss: 0.0487 - val_q0_75_loss: 0.0381 - val_q0_95_loss: 0.0145\n",
      "Epoch 21/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1704 - q0_05_loss: 0.0164 - q0_25_loss: 0.0385 - q0_5_loss: 0.0455 - q0_75_loss: 0.0373 - q0_95_loss: 0.0150 - val_loss: 0.1742 - val_q0_05_loss: 0.0168 - val_q0_25_loss: 0.0392 - val_q0_5_loss: 0.0466 - val_q0_75_loss: 0.0385 - val_q0_95_loss: 0.0155\n",
      "Epoch 22/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1696 - q0_05_loss: 0.0163 - q0_25_loss: 0.0384 - q0_5_loss: 0.0453 - q0_75_loss: 0.0371 - q0_95_loss: 0.0148 - val_loss: 0.1687 - val_q0_05_loss: 0.0161 - val_q0_25_loss: 0.0380 - val_q0_5_loss: 0.0455 - val_q0_75_loss: 0.0367 - val_q0_95_loss: 0.0146\n",
      "Epoch 23/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1687 - q0_05_loss: 0.0163 - q0_25_loss: 0.0381 - q0_5_loss: 0.0450 - q0_75_loss: 0.0369 - q0_95_loss: 0.0147 - val_loss: 0.1633 - val_q0_05_loss: 0.0153 - val_q0_25_loss: 0.0359 - val_q0_5_loss: 0.0434 - val_q0_75_loss: 0.0361 - val_q0_95_loss: 0.0148\n",
      "Epoch 24/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1680 - q0_05_loss: 0.0163 - q0_25_loss: 0.0380 - q0_5_loss: 0.0448 - q0_75_loss: 0.0366 - q0_95_loss: 0.0145 - val_loss: 0.1664 - val_q0_05_loss: 0.0165 - val_q0_25_loss: 0.0378 - val_q0_5_loss: 0.0439 - val_q0_75_loss: 0.0358 - val_q0_95_loss: 0.0145\n",
      "Epoch 25/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1681 - q0_05_loss: 0.0162 - q0_25_loss: 0.0380 - q0_5_loss: 0.0448 - q0_75_loss: 0.0367 - q0_95_loss: 0.0146 - val_loss: 0.1677 - val_q0_05_loss: 0.0147 - val_q0_25_loss: 0.0372 - val_q0_5_loss: 0.0452 - val_q0_75_loss: 0.0375 - val_q0_95_loss: 0.0153\n",
      "Epoch 26/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1679 - q0_05_loss: 0.0161 - q0_25_loss: 0.0378 - q0_5_loss: 0.0447 - q0_75_loss: 0.0367 - q0_95_loss: 0.0147 - val_loss: 0.1701 - val_q0_05_loss: 0.0161 - val_q0_25_loss: 0.0384 - val_q0_5_loss: 0.0453 - val_q0_75_loss: 0.0375 - val_q0_95_loss: 0.0147\n",
      "Epoch 27/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1676 - q0_05_loss: 0.0160 - q0_25_loss: 0.0377 - q0_5_loss: 0.0445 - q0_75_loss: 0.0366 - q0_95_loss: 0.0148 - val_loss: 0.1679 - val_q0_05_loss: 0.0162 - val_q0_25_loss: 0.0381 - val_q0_5_loss: 0.0442 - val_q0_75_loss: 0.0361 - val_q0_95_loss: 0.0154\n",
      "Epoch 28/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1672 - q0_05_loss: 0.0162 - q0_25_loss: 0.0378 - q0_5_loss: 0.0444 - q0_75_loss: 0.0364 - q0_95_loss: 0.0144 - val_loss: 0.1667 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0379 - val_q0_5_loss: 0.0448 - val_q0_75_loss: 0.0359 - val_q0_95_loss: 0.0144\n",
      "Epoch 29/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1671 - q0_05_loss: 0.0161 - q0_25_loss: 0.0377 - q0_5_loss: 0.0444 - q0_75_loss: 0.0363 - q0_95_loss: 0.0144 - val_loss: 0.1697 - val_q0_05_loss: 0.0170 - val_q0_25_loss: 0.0385 - val_q0_5_loss: 0.0450 - val_q0_75_loss: 0.0366 - val_q0_95_loss: 0.0145\n",
      "Epoch 30/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1664 - q0_05_loss: 0.0160 - q0_25_loss: 0.0375 - q0_5_loss: 0.0443 - q0_75_loss: 0.0362 - q0_95_loss: 0.0142 - val_loss: 0.1702 - val_q0_05_loss: 0.0159 - val_q0_25_loss: 0.0386 - val_q0_5_loss: 0.0457 - val_q0_75_loss: 0.0374 - val_q0_95_loss: 0.0145\n",
      "Epoch 31/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1659 - q0_05_loss: 0.0160 - q0_25_loss: 0.0374 - q0_5_loss: 0.0440 - q0_75_loss: 0.0360 - q0_95_loss: 0.0143 - val_loss: 0.1873 - val_q0_05_loss: 0.0159 - val_q0_25_loss: 0.0425 - val_q0_5_loss: 0.0518 - val_q0_75_loss: 0.0433 - val_q0_95_loss: 0.0156\n",
      "Epoch 32/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1659 - q0_05_loss: 0.0159 - q0_25_loss: 0.0373 - q0_5_loss: 0.0440 - q0_75_loss: 0.0361 - q0_95_loss: 0.0143 - val_loss: 0.1754 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0395 - val_q0_5_loss: 0.0471 - val_q0_75_loss: 0.0390 - val_q0_95_loss: 0.0160\n",
      "Epoch 33/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1651 - q0_05_loss: 0.0158 - q0_25_loss: 0.0371 - q0_5_loss: 0.0439 - q0_75_loss: 0.0359 - q0_95_loss: 0.0141 - val_loss: 0.1607 - val_q0_05_loss: 0.0161 - val_q0_25_loss: 0.0363 - val_q0_5_loss: 0.0421 - val_q0_75_loss: 0.0344 - val_q0_95_loss: 0.0135\n",
      "Epoch 34/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1657 - q0_05_loss: 0.0159 - q0_25_loss: 0.0373 - q0_5_loss: 0.0439 - q0_75_loss: 0.0360 - q0_95_loss: 0.0142 - val_loss: 0.1695 - val_q0_05_loss: 0.0168 - val_q0_25_loss: 0.0390 - val_q0_5_loss: 0.0448 - val_q0_75_loss: 0.0362 - val_q0_95_loss: 0.0142\n",
      "Epoch 35/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1648 - q0_05_loss: 0.0157 - q0_25_loss: 0.0371 - q0_5_loss: 0.0437 - q0_75_loss: 0.0358 - q0_95_loss: 0.0142 - val_loss: 0.1749 - val_q0_05_loss: 0.0168 - val_q0_25_loss: 0.0413 - val_q0_5_loss: 0.0481 - val_q0_75_loss: 0.0371 - val_q0_95_loss: 0.0132\n",
      "Epoch 36/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1645 - q0_05_loss: 0.0158 - q0_25_loss: 0.0369 - q0_5_loss: 0.0435 - q0_75_loss: 0.0357 - q0_95_loss: 0.0142 - val_loss: 0.1640 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0373 - val_q0_5_loss: 0.0438 - val_q0_75_loss: 0.0352 - val_q0_95_loss: 0.0138\n",
      "Epoch 37/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1648 - q0_05_loss: 0.0158 - q0_25_loss: 0.0369 - q0_5_loss: 0.0436 - q0_75_loss: 0.0358 - q0_95_loss: 0.0143 - val_loss: 0.1613 - val_q0_05_loss: 0.0159 - val_q0_25_loss: 0.0359 - val_q0_5_loss: 0.0424 - val_q0_75_loss: 0.0347 - val_q0_95_loss: 0.0138\n",
      "Epoch 38/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1642 - q0_05_loss: 0.0157 - q0_25_loss: 0.0368 - q0_5_loss: 0.0434 - q0_75_loss: 0.0356 - q0_95_loss: 0.0141 - val_loss: 0.1667 - val_q0_05_loss: 0.0150 - val_q0_25_loss: 0.0375 - val_q0_5_loss: 0.0443 - val_q0_75_loss: 0.0367 - val_q0_95_loss: 0.0147\n",
      "Epoch 39/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1636 - q0_05_loss: 0.0156 - q0_25_loss: 0.0367 - q0_5_loss: 0.0433 - q0_75_loss: 0.0355 - q0_95_loss: 0.0140 - val_loss: 0.1699 - val_q0_05_loss: 0.0161 - val_q0_25_loss: 0.0376 - val_q0_5_loss: 0.0448 - val_q0_75_loss: 0.0374 - val_q0_95_loss: 0.0153\n",
      "Epoch 40/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1643 - q0_05_loss: 0.0158 - q0_25_loss: 0.0368 - q0_5_loss: 0.0434 - q0_75_loss: 0.0356 - q0_95_loss: 0.0141 - val_loss: 0.1590 - val_q0_05_loss: 0.0150 - val_q0_25_loss: 0.0352 - val_q0_5_loss: 0.0417 - val_q0_75_loss: 0.0346 - val_q0_95_loss: 0.0139\n",
      "Epoch 41/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1642 - q0_05_loss: 0.0158 - q0_25_loss: 0.0368 - q0_5_loss: 0.0433 - q0_75_loss: 0.0355 - q0_95_loss: 0.0141 - val_loss: 0.1664 - val_q0_05_loss: 0.0155 - val_q0_25_loss: 0.0366 - val_q0_5_loss: 0.0447 - val_q0_75_loss: 0.0368 - val_q0_95_loss: 0.0141\n",
      "Epoch 42/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1630 - q0_05_loss: 0.0156 - q0_25_loss: 0.0364 - q0_5_loss: 0.0430 - q0_75_loss: 0.0353 - q0_95_loss: 0.0141 - val_loss: 0.1776 - val_q0_05_loss: 0.0167 - val_q0_25_loss: 0.0397 - val_q0_5_loss: 0.0483 - val_q0_75_loss: 0.0391 - val_q0_95_loss: 0.0153\n",
      "Epoch 43/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1637 - q0_05_loss: 0.0159 - q0_25_loss: 0.0367 - q0_5_loss: 0.0431 - q0_75_loss: 0.0353 - q0_95_loss: 0.0140 - val_loss: 0.1644 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0371 - val_q0_5_loss: 0.0437 - val_q0_75_loss: 0.0359 - val_q0_95_loss: 0.0134\n",
      "Epoch 44/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1625 - q0_05_loss: 0.0156 - q0_25_loss: 0.0364 - q0_5_loss: 0.0429 - q0_75_loss: 0.0351 - q0_95_loss: 0.0138 - val_loss: 0.1602 - val_q0_05_loss: 0.0148 - val_q0_25_loss: 0.0352 - val_q0_5_loss: 0.0419 - val_q0_75_loss: 0.0351 - val_q0_95_loss: 0.0144\n",
      "Epoch 45/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1632 - q0_05_loss: 0.0157 - q0_25_loss: 0.0367 - q0_5_loss: 0.0430 - q0_75_loss: 0.0352 - q0_95_loss: 0.0139 - val_loss: 0.1612 - val_q0_05_loss: 0.0159 - val_q0_25_loss: 0.0361 - val_q0_5_loss: 0.0424 - val_q0_75_loss: 0.0347 - val_q0_95_loss: 0.0134\n",
      "Epoch 46/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1633 - q0_05_loss: 0.0156 - q0_25_loss: 0.0365 - q0_5_loss: 0.0431 - q0_75_loss: 0.0353 - q0_95_loss: 0.0141 - val_loss: 0.1590 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0362 - val_q0_5_loss: 0.0417 - val_q0_75_loss: 0.0338 - val_q0_95_loss: 0.0131\n",
      "Epoch 47/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1621 - q0_05_loss: 0.0156 - q0_25_loss: 0.0363 - q0_5_loss: 0.0428 - q0_75_loss: 0.0350 - q0_95_loss: 0.0138 - val_loss: 0.1867 - val_q0_05_loss: 0.0185 - val_q0_25_loss: 0.0433 - val_q0_5_loss: 0.0510 - val_q0_75_loss: 0.0404 - val_q0_95_loss: 0.0148\n",
      "Epoch 48/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1624 - q0_05_loss: 0.0156 - q0_25_loss: 0.0363 - q0_5_loss: 0.0428 - q0_75_loss: 0.0350 - q0_95_loss: 0.0139 - val_loss: 0.1675 - val_q0_05_loss: 0.0150 - val_q0_25_loss: 0.0371 - val_q0_5_loss: 0.0453 - val_q0_75_loss: 0.0366 - val_q0_95_loss: 0.0145\n",
      "Epoch 49/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1629 - q0_05_loss: 0.0155 - q0_25_loss: 0.0364 - q0_5_loss: 0.0429 - q0_75_loss: 0.0353 - q0_95_loss: 0.0141 - val_loss: 0.1617 - val_q0_05_loss: 0.0154 - val_q0_25_loss: 0.0359 - val_q0_5_loss: 0.0428 - val_q0_75_loss: 0.0350 - val_q0_95_loss: 0.0138\n",
      "Epoch 50/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1608 - q0_05_loss: 0.0153 - q0_25_loss: 0.0359 - q0_5_loss: 0.0424 - q0_75_loss: 0.0347 - q0_95_loss: 0.0137 - val_loss: 0.1665 - val_q0_05_loss: 0.0169 - val_q0_25_loss: 0.0381 - val_q0_5_loss: 0.0438 - val_q0_75_loss: 0.0353 - val_q0_95_loss: 0.0137\n",
      "Epoch 51/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1625 - q0_05_loss: 0.0156 - q0_25_loss: 0.0363 - q0_5_loss: 0.0428 - q0_75_loss: 0.0351 - q0_95_loss: 0.0139 - val_loss: 0.1681 - val_q0_05_loss: 0.0155 - val_q0_25_loss: 0.0369 - val_q0_5_loss: 0.0450 - val_q0_75_loss: 0.0374 - val_q0_95_loss: 0.0146\n",
      "Epoch 52/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1613 - q0_05_loss: 0.0154 - q0_25_loss: 0.0361 - q0_5_loss: 0.0426 - q0_75_loss: 0.0348 - q0_95_loss: 0.0137 - val_loss: 0.1689 - val_q0_05_loss: 0.0154 - val_q0_25_loss: 0.0375 - val_q0_5_loss: 0.0447 - val_q0_75_loss: 0.0381 - val_q0_95_loss: 0.0144\n",
      "Epoch 53/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1612 - q0_05_loss: 0.0154 - q0_25_loss: 0.0360 - q0_5_loss: 0.0425 - q0_75_loss: 0.0348 - q0_95_loss: 0.0138 - val_loss: 0.1644 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0369 - val_q0_5_loss: 0.0432 - val_q0_75_loss: 0.0355 - val_q0_95_loss: 0.0144\n",
      "Epoch 54/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1620 - q0_05_loss: 0.0154 - q0_25_loss: 0.0360 - q0_5_loss: 0.0427 - q0_75_loss: 0.0351 - q0_95_loss: 0.0140 - val_loss: 0.1671 - val_q0_05_loss: 0.0168 - val_q0_25_loss: 0.0389 - val_q0_5_loss: 0.0445 - val_q0_75_loss: 0.0349 - val_q0_95_loss: 0.0133\n",
      "Epoch 55/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1615 - q0_05_loss: 0.0155 - q0_25_loss: 0.0361 - q0_5_loss: 0.0425 - q0_75_loss: 0.0348 - q0_95_loss: 0.0138 - val_loss: 0.1615 - val_q0_05_loss: 0.0164 - val_q0_25_loss: 0.0372 - val_q0_5_loss: 0.0425 - val_q0_75_loss: 0.0337 - val_q0_95_loss: 0.0128\n",
      "Epoch 56/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1620 - q0_05_loss: 0.0155 - q0_25_loss: 0.0363 - q0_5_loss: 0.0426 - q0_75_loss: 0.0349 - q0_95_loss: 0.0138 - val_loss: 0.1620 - val_q0_05_loss: 0.0152 - val_q0_25_loss: 0.0361 - val_q0_5_loss: 0.0430 - val_q0_75_loss: 0.0351 - val_q0_95_loss: 0.0136\n",
      "Epoch 57/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1613 - q0_05_loss: 0.0156 - q0_25_loss: 0.0361 - q0_5_loss: 0.0424 - q0_75_loss: 0.0346 - q0_95_loss: 0.0136 - val_loss: 0.1614 - val_q0_05_loss: 0.0154 - val_q0_25_loss: 0.0364 - val_q0_5_loss: 0.0428 - val_q0_75_loss: 0.0346 - val_q0_95_loss: 0.0132\n",
      "Epoch 58/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1626 - q0_05_loss: 0.0156 - q0_25_loss: 0.0364 - q0_5_loss: 0.0428 - q0_75_loss: 0.0350 - q0_95_loss: 0.0138 - val_loss: 0.1576 - val_q0_05_loss: 0.0152 - val_q0_25_loss: 0.0355 - val_q0_5_loss: 0.0411 - val_q0_75_loss: 0.0335 - val_q0_95_loss: 0.0132\n",
      "Epoch 59/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1614 - q0_05_loss: 0.0154 - q0_25_loss: 0.0361 - q0_5_loss: 0.0424 - q0_75_loss: 0.0347 - q0_95_loss: 0.0137 - val_loss: 0.1616 - val_q0_05_loss: 0.0154 - val_q0_25_loss: 0.0366 - val_q0_5_loss: 0.0428 - val_q0_75_loss: 0.0343 - val_q0_95_loss: 0.0134\n",
      "Epoch 60/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1605 - q0_05_loss: 0.0152 - q0_25_loss: 0.0357 - q0_5_loss: 0.0422 - q0_75_loss: 0.0346 - q0_95_loss: 0.0137 - val_loss: 0.1638 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0367 - val_q0_5_loss: 0.0433 - val_q0_75_loss: 0.0353 - val_q0_95_loss: 0.0139\n",
      "Epoch 61/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1616 - q0_05_loss: 0.0155 - q0_25_loss: 0.0360 - q0_5_loss: 0.0424 - q0_75_loss: 0.0348 - q0_95_loss: 0.0138 - val_loss: 0.1638 - val_q0_05_loss: 0.0162 - val_q0_25_loss: 0.0371 - val_q0_5_loss: 0.0428 - val_q0_75_loss: 0.0346 - val_q0_95_loss: 0.0140\n",
      "Epoch 62/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1608 - q0_05_loss: 0.0152 - q0_25_loss: 0.0358 - q0_5_loss: 0.0423 - q0_75_loss: 0.0346 - q0_95_loss: 0.0138 - val_loss: 0.1584 - val_q0_05_loss: 0.0149 - val_q0_25_loss: 0.0348 - val_q0_5_loss: 0.0418 - val_q0_75_loss: 0.0344 - val_q0_95_loss: 0.0134\n",
      "Epoch 63/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1604 - q0_05_loss: 0.0153 - q0_25_loss: 0.0358 - q0_5_loss: 0.0422 - q0_75_loss: 0.0345 - q0_95_loss: 0.0136 - val_loss: 0.1639 - val_q0_05_loss: 0.0155 - val_q0_25_loss: 0.0366 - val_q0_5_loss: 0.0436 - val_q0_75_loss: 0.0356 - val_q0_95_loss: 0.0136\n",
      "Epoch 64/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1607 - q0_05_loss: 0.0154 - q0_25_loss: 0.0358 - q0_5_loss: 0.0422 - q0_75_loss: 0.0345 - q0_95_loss: 0.0136 - val_loss: 0.1669 - val_q0_05_loss: 0.0160 - val_q0_25_loss: 0.0371 - val_q0_5_loss: 0.0439 - val_q0_75_loss: 0.0361 - val_q0_95_loss: 0.0145\n",
      "Epoch 65/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1603 - q0_05_loss: 0.0153 - q0_25_loss: 0.0356 - q0_5_loss: 0.0421 - q0_75_loss: 0.0345 - q0_95_loss: 0.0137 - val_loss: 0.1569 - val_q0_05_loss: 0.0156 - val_q0_25_loss: 0.0355 - val_q0_5_loss: 0.0409 - val_q0_75_loss: 0.0332 - val_q0_95_loss: 0.0125\n",
      "Epoch 66/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1601 - q0_05_loss: 0.0152 - q0_25_loss: 0.0356 - q0_5_loss: 0.0420 - q0_75_loss: 0.0345 - q0_95_loss: 0.0137 - val_loss: 0.1567 - val_q0_05_loss: 0.0146 - val_q0_25_loss: 0.0346 - val_q0_5_loss: 0.0411 - val_q0_75_loss: 0.0339 - val_q0_95_loss: 0.0135\n",
      "Epoch 67/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1600 - q0_05_loss: 0.0152 - q0_25_loss: 0.0355 - q0_5_loss: 0.0420 - q0_75_loss: 0.0345 - q0_95_loss: 0.0137 - val_loss: 0.1597 - val_q0_05_loss: 0.0150 - val_q0_25_loss: 0.0356 - val_q0_5_loss: 0.0420 - val_q0_75_loss: 0.0346 - val_q0_95_loss: 0.0134\n",
      "Epoch 68/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1598 - q0_05_loss: 0.0153 - q0_25_loss: 0.0356 - q0_5_loss: 0.0419 - q0_75_loss: 0.0344 - q0_95_loss: 0.0136 - val_loss: 0.1646 - val_q0_05_loss: 0.0158 - val_q0_25_loss: 0.0367 - val_q0_5_loss: 0.0429 - val_q0_75_loss: 0.0353 - val_q0_95_loss: 0.0147\n",
      "Epoch 69/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1612 - q0_05_loss: 0.0154 - q0_25_loss: 0.0359 - q0_5_loss: 0.0423 - q0_75_loss: 0.0347 - q0_95_loss: 0.0138 - val_loss: 0.1655 - val_q0_05_loss: 0.0157 - val_q0_25_loss: 0.0367 - val_q0_5_loss: 0.0441 - val_q0_75_loss: 0.0361 - val_q0_95_loss: 0.0137\n",
      "Epoch 70/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1604 - q0_05_loss: 0.0153 - q0_25_loss: 0.0357 - q0_5_loss: 0.0421 - q0_75_loss: 0.0345 - q0_95_loss: 0.0137 - val_loss: 0.1582 - val_q0_05_loss: 0.0149 - val_q0_25_loss: 0.0348 - val_q0_5_loss: 0.0410 - val_q0_75_loss: 0.0343 - val_q0_95_loss: 0.0140\n",
      "Epoch 71/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1598 - q0_05_loss: 0.0153 - q0_25_loss: 0.0355 - q0_5_loss: 0.0419 - q0_75_loss: 0.0343 - q0_95_loss: 0.0136 - val_loss: 0.1607 - val_q0_05_loss: 0.0151 - val_q0_25_loss: 0.0361 - val_q0_5_loss: 0.0426 - val_q0_75_loss: 0.0344 - val_q0_95_loss: 0.0134\n",
      "Epoch 72/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1594 - q0_05_loss: 0.0150 - q0_25_loss: 0.0353 - q0_5_loss: 0.0418 - q0_75_loss: 0.0344 - q0_95_loss: 0.0137 - val_loss: 0.1595 - val_q0_05_loss: 0.0149 - val_q0_25_loss: 0.0352 - val_q0_5_loss: 0.0418 - val_q0_75_loss: 0.0343 - val_q0_95_loss: 0.0140\n",
      "Epoch 73/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1602 - q0_05_loss: 0.0151 - q0_25_loss: 0.0355 - q0_5_loss: 0.0421 - q0_75_loss: 0.0346 - q0_95_loss: 0.0137 - val_loss: 0.1697 - val_q0_05_loss: 0.0198 - val_q0_25_loss: 0.0399 - val_q0_5_loss: 0.0439 - val_q0_75_loss: 0.0341 - val_q0_95_loss: 0.0128\n",
      "Epoch 74/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1601 - q0_05_loss: 0.0154 - q0_25_loss: 0.0356 - q0_5_loss: 0.0418 - q0_75_loss: 0.0343 - q0_95_loss: 0.0137 - val_loss: 0.1679 - val_q0_05_loss: 0.0148 - val_q0_25_loss: 0.0371 - val_q0_5_loss: 0.0452 - val_q0_75_loss: 0.0374 - val_q0_95_loss: 0.0141\n",
      "Epoch 75/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1602 - q0_05_loss: 0.0153 - q0_25_loss: 0.0355 - q0_5_loss: 0.0419 - q0_75_loss: 0.0345 - q0_95_loss: 0.0137 - val_loss: 0.1644 - val_q0_05_loss: 0.0167 - val_q0_25_loss: 0.0384 - val_q0_5_loss: 0.0431 - val_q0_75_loss: 0.0337 - val_q0_95_loss: 0.0131\n",
      "Epoch 76/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1592 - q0_05_loss: 0.0151 - q0_25_loss: 0.0353 - q0_5_loss: 0.0417 - q0_75_loss: 0.0342 - q0_95_loss: 0.0135 - val_loss: 0.1656 - val_q0_05_loss: 0.0152 - val_q0_25_loss: 0.0368 - val_q0_5_loss: 0.0440 - val_q0_75_loss: 0.0361 - val_q0_95_loss: 0.0143\n",
      "Epoch 77/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1591 - q0_05_loss: 0.0152 - q0_25_loss: 0.0353 - q0_5_loss: 0.0417 - q0_75_loss: 0.0341 - q0_95_loss: 0.0136 - val_loss: 0.1550 - val_q0_05_loss: 0.0149 - val_q0_25_loss: 0.0345 - val_q0_5_loss: 0.0403 - val_q0_75_loss: 0.0329 - val_q0_95_loss: 0.0131\n",
      "Epoch 78/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1601 - q0_05_loss: 0.0152 - q0_25_loss: 0.0356 - q0_5_loss: 0.0420 - q0_75_loss: 0.0345 - q0_95_loss: 0.0136 - val_loss: 0.1613 - val_q0_05_loss: 0.0150 - val_q0_25_loss: 0.0356 - val_q0_5_loss: 0.0423 - val_q0_75_loss: 0.0350 - val_q0_95_loss: 0.0142\n",
      "Epoch 79/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1581 - q0_05_loss: 0.0150 - q0_25_loss: 0.0351 - q0_5_loss: 0.0415 - q0_75_loss: 0.0340 - q0_95_loss: 0.0133 - val_loss: 0.1583 - val_q0_05_loss: 0.0145 - val_q0_25_loss: 0.0348 - val_q0_5_loss: 0.0414 - val_q0_75_loss: 0.0344 - val_q0_95_loss: 0.0140\n",
      "Epoch 80/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1595 - q0_05_loss: 0.0152 - q0_25_loss: 0.0354 - q0_5_loss: 0.0418 - q0_75_loss: 0.0342 - q0_95_loss: 0.0136 - val_loss: 0.1594 - val_q0_05_loss: 0.0150 - val_q0_25_loss: 0.0355 - val_q0_5_loss: 0.0420 - val_q0_75_loss: 0.0343 - val_q0_95_loss: 0.0133\n",
      "Epoch 81/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1600 - q0_05_loss: 0.0153 - q0_25_loss: 0.0356 - q0_5_loss: 0.0419 - q0_75_loss: 0.0343 - q0_95_loss: 0.0136 - val_loss: 0.1686 - val_q0_05_loss: 0.0163 - val_q0_25_loss: 0.0383 - val_q0_5_loss: 0.0452 - val_q0_75_loss: 0.0361 - val_q0_95_loss: 0.0133\n",
      "Epoch 82/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1586 - q0_05_loss: 0.0149 - q0_25_loss: 0.0352 - q0_5_loss: 0.0416 - q0_75_loss: 0.0341 - q0_95_loss: 0.0135 - val_loss: 0.1561 - val_q0_05_loss: 0.0155 - val_q0_25_loss: 0.0348 - val_q0_5_loss: 0.0405 - val_q0_75_loss: 0.0328 - val_q0_95_loss: 0.0131\n",
      "Epoch 83/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1591 - q0_05_loss: 0.0151 - q0_25_loss: 0.0353 - q0_5_loss: 0.0417 - q0_75_loss: 0.0342 - q0_95_loss: 0.0136 - val_loss: 0.1571 - val_q0_05_loss: 0.0149 - val_q0_25_loss: 0.0350 - val_q0_5_loss: 0.0411 - val_q0_75_loss: 0.0338 - val_q0_95_loss: 0.0130\n",
      "Epoch 84/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1586 - q0_05_loss: 0.0152 - q0_25_loss: 0.0352 - q0_5_loss: 0.0415 - q0_75_loss: 0.0340 - q0_95_loss: 0.0134 - val_loss: 0.1605 - val_q0_05_loss: 0.0149 - val_q0_25_loss: 0.0356 - val_q0_5_loss: 0.0416 - val_q0_75_loss: 0.0353 - val_q0_95_loss: 0.0137\n",
      "Epoch 85/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1584 - q0_05_loss: 0.0151 - q0_25_loss: 0.0352 - q0_5_loss: 0.0415 - q0_75_loss: 0.0340 - q0_95_loss: 0.0135 - val_loss: 0.1602 - val_q0_05_loss: 0.0149 - val_q0_25_loss: 0.0349 - val_q0_5_loss: 0.0429 - val_q0_75_loss: 0.0349 - val_q0_95_loss: 0.0134\n",
      "Epoch 86/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1592 - q0_05_loss: 0.0151 - q0_25_loss: 0.0353 - q0_5_loss: 0.0417 - q0_75_loss: 0.0342 - q0_95_loss: 0.0137 - val_loss: 0.1571 - val_q0_05_loss: 0.0154 - val_q0_25_loss: 0.0357 - val_q0_5_loss: 0.0409 - val_q0_75_loss: 0.0330 - val_q0_95_loss: 0.0128\n",
      "Epoch 87/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1585 - q0_05_loss: 0.0150 - q0_25_loss: 0.0351 - q0_5_loss: 0.0415 - q0_75_loss: 0.0341 - q0_95_loss: 0.0135 - val_loss: 0.1621 - val_q0_05_loss: 0.0153 - val_q0_25_loss: 0.0366 - val_q0_5_loss: 0.0432 - val_q0_75_loss: 0.0345 - val_q0_95_loss: 0.0132\n",
      "Epoch 88/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1581 - q0_05_loss: 0.0149 - q0_25_loss: 0.0350 - q0_5_loss: 0.0414 - q0_75_loss: 0.0340 - q0_95_loss: 0.0135 - val_loss: 0.1564 - val_q0_05_loss: 0.0148 - val_q0_25_loss: 0.0348 - val_q0_5_loss: 0.0410 - val_q0_75_loss: 0.0335 - val_q0_95_loss: 0.0130\n",
      "Epoch 89/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1582 - q0_05_loss: 0.0151 - q0_25_loss: 0.0351 - q0_5_loss: 0.0414 - q0_75_loss: 0.0339 - q0_95_loss: 0.0134 - val_loss: 0.1575 - val_q0_05_loss: 0.0155 - val_q0_25_loss: 0.0354 - val_q0_5_loss: 0.0412 - val_q0_75_loss: 0.0332 - val_q0_95_loss: 0.0129\n",
      "Epoch 90/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1575 - q0_05_loss: 0.0149 - q0_25_loss: 0.0349 - q0_5_loss: 0.0412 - q0_75_loss: 0.0338 - q0_95_loss: 0.0134 - val_loss: 0.1510 - val_q0_05_loss: 0.0147 - val_q0_25_loss: 0.0340 - val_q0_5_loss: 0.0394 - val_q0_75_loss: 0.0316 - val_q0_95_loss: 0.0119\n",
      "Epoch 91/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1581 - q0_05_loss: 0.0150 - q0_25_loss: 0.0350 - q0_5_loss: 0.0414 - q0_75_loss: 0.0339 - q0_95_loss: 0.0134 - val_loss: 0.1643 - val_q0_05_loss: 0.0148 - val_q0_25_loss: 0.0365 - val_q0_5_loss: 0.0436 - val_q0_75_loss: 0.0358 - val_q0_95_loss: 0.0142\n",
      "Epoch 92/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1578 - q0_05_loss: 0.0149 - q0_25_loss: 0.0350 - q0_5_loss: 0.0413 - q0_75_loss: 0.0338 - q0_95_loss: 0.0134 - val_loss: 0.1721 - val_q0_05_loss: 0.0151 - val_q0_25_loss: 0.0364 - val_q0_5_loss: 0.0456 - val_q0_75_loss: 0.0400 - val_q0_95_loss: 0.0154\n",
      "Epoch 93/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1587 - q0_05_loss: 0.0151 - q0_25_loss: 0.0352 - q0_5_loss: 0.0415 - q0_75_loss: 0.0339 - q0_95_loss: 0.0133 - val_loss: 0.1578 - val_q0_05_loss: 0.0161 - val_q0_25_loss: 0.0360 - val_q0_5_loss: 0.0413 - val_q0_75_loss: 0.0326 - val_q0_95_loss: 0.0124\n",
      "Epoch 94/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1580 - q0_05_loss: 0.0150 - q0_25_loss: 0.0350 - q0_5_loss: 0.0413 - q0_75_loss: 0.0339 - q0_95_loss: 0.0134 - val_loss: 0.1540 - val_q0_05_loss: 0.0148 - val_q0_25_loss: 0.0339 - val_q0_5_loss: 0.0401 - val_q0_75_loss: 0.0329 - val_q0_95_loss: 0.0129\n",
      "Epoch 95/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1579 - q0_05_loss: 0.0150 - q0_25_loss: 0.0350 - q0_5_loss: 0.0413 - q0_75_loss: 0.0338 - q0_95_loss: 0.0133 - val_loss: 0.1579 - val_q0_05_loss: 0.0137 - val_q0_25_loss: 0.0341 - val_q0_5_loss: 0.0414 - val_q0_75_loss: 0.0347 - val_q0_95_loss: 0.0144\n",
      "Epoch 96/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1585 - q0_05_loss: 0.0150 - q0_25_loss: 0.0351 - q0_5_loss: 0.0414 - q0_75_loss: 0.0339 - q0_95_loss: 0.0135 - val_loss: 0.1640 - val_q0_05_loss: 0.0154 - val_q0_25_loss: 0.0356 - val_q0_5_loss: 0.0432 - val_q0_75_loss: 0.0360 - val_q0_95_loss: 0.0142\n",
      "Epoch 97/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1585 - q0_05_loss: 0.0149 - q0_25_loss: 0.0350 - q0_5_loss: 0.0415 - q0_75_loss: 0.0340 - q0_95_loss: 0.0135 - val_loss: 0.1581 - val_q0_05_loss: 0.0155 - val_q0_25_loss: 0.0351 - val_q0_5_loss: 0.0412 - val_q0_75_loss: 0.0333 - val_q0_95_loss: 0.0135\n",
      "Epoch 98/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1579 - q0_05_loss: 0.0149 - q0_25_loss: 0.0349 - q0_5_loss: 0.0412 - q0_75_loss: 0.0339 - q0_95_loss: 0.0134 - val_loss: 0.1722 - val_q0_05_loss: 0.0167 - val_q0_25_loss: 0.0384 - val_q0_5_loss: 0.0459 - val_q0_75_loss: 0.0377 - val_q0_95_loss: 0.0139\n",
      "Epoch 99/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1580 - q0_05_loss: 0.0150 - q0_25_loss: 0.0349 - q0_5_loss: 0.0412 - q0_75_loss: 0.0338 - q0_95_loss: 0.0135 - val_loss: 0.1571 - val_q0_05_loss: 0.0145 - val_q0_25_loss: 0.0346 - val_q0_5_loss: 0.0410 - val_q0_75_loss: 0.0340 - val_q0_95_loss: 0.0135\n",
      "Epoch 100/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1579 - q0_05_loss: 0.0149 - q0_25_loss: 0.0349 - q0_5_loss: 0.0413 - q0_75_loss: 0.0339 - q0_95_loss: 0.0134 - val_loss: 0.1647 - val_q0_05_loss: 0.0173 - val_q0_25_loss: 0.0378 - val_q0_5_loss: 0.0431 - val_q0_75_loss: 0.0345 - val_q0_95_loss: 0.0125\n",
      "Epoch 101/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1582 - q0_05_loss: 0.0150 - q0_25_loss: 0.0350 - q0_5_loss: 0.0413 - q0_75_loss: 0.0338 - q0_95_loss: 0.0134 - val_loss: 0.1565 - val_q0_05_loss: 0.0142 - val_q0_25_loss: 0.0339 - val_q0_5_loss: 0.0407 - val_q0_75_loss: 0.0345 - val_q0_95_loss: 0.0136\n",
      "Epoch 102/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1565 - q0_05_loss: 0.0148 - q0_25_loss: 0.0346 - q0_5_loss: 0.0408 - q0_75_loss: 0.0335 - q0_95_loss: 0.0133 - val_loss: 0.1613 - val_q0_05_loss: 0.0147 - val_q0_25_loss: 0.0358 - val_q0_5_loss: 0.0422 - val_q0_75_loss: 0.0354 - val_q0_95_loss: 0.0138\n",
      "Epoch 103/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1573 - q0_05_loss: 0.0148 - q0_25_loss: 0.0347 - q0_5_loss: 0.0411 - q0_75_loss: 0.0337 - q0_95_loss: 0.0134 - val_loss: 0.1592 - val_q0_05_loss: 0.0152 - val_q0_25_loss: 0.0358 - val_q0_5_loss: 0.0420 - val_q0_75_loss: 0.0338 - val_q0_95_loss: 0.0129\n",
      "Epoch 104/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1576 - q0_05_loss: 0.0149 - q0_25_loss: 0.0349 - q0_5_loss: 0.0412 - q0_75_loss: 0.0337 - q0_95_loss: 0.0133 - val_loss: 0.1586 - val_q0_05_loss: 0.0145 - val_q0_25_loss: 0.0348 - val_q0_5_loss: 0.0412 - val_q0_75_loss: 0.0343 - val_q0_95_loss: 0.0141\n",
      "Epoch 105/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1568 - q0_05_loss: 0.0148 - q0_25_loss: 0.0346 - q0_5_loss: 0.0409 - q0_75_loss: 0.0336 - q0_95_loss: 0.0133 - val_loss: 0.1528 - val_q0_05_loss: 0.0145 - val_q0_25_loss: 0.0336 - val_q0_5_loss: 0.0399 - val_q0_75_loss: 0.0325 - val_q0_95_loss: 0.0128\n",
      "Epoch 106/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1570 - q0_05_loss: 0.0148 - q0_25_loss: 0.0347 - q0_5_loss: 0.0411 - q0_75_loss: 0.0336 - q0_95_loss: 0.0133 - val_loss: 0.1647 - val_q0_05_loss: 0.0158 - val_q0_25_loss: 0.0369 - val_q0_5_loss: 0.0435 - val_q0_75_loss: 0.0350 - val_q0_95_loss: 0.0140\n",
      "Epoch 107/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1580 - q0_05_loss: 0.0151 - q0_25_loss: 0.0350 - q0_5_loss: 0.0412 - q0_75_loss: 0.0338 - q0_95_loss: 0.0132 - val_loss: 0.1691 - val_q0_05_loss: 0.0152 - val_q0_25_loss: 0.0371 - val_q0_5_loss: 0.0448 - val_q0_75_loss: 0.0370 - val_q0_95_loss: 0.0152\n",
      "Epoch 108/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1570 - q0_05_loss: 0.0149 - q0_25_loss: 0.0347 - q0_5_loss: 0.0409 - q0_75_loss: 0.0336 - q0_95_loss: 0.0133 - val_loss: 0.1571 - val_q0_05_loss: 0.0143 - val_q0_25_loss: 0.0349 - val_q0_5_loss: 0.0415 - val_q0_75_loss: 0.0336 - val_q0_95_loss: 0.0131\n",
      "Epoch 109/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1572 - q0_05_loss: 0.0149 - q0_25_loss: 0.0347 - q0_5_loss: 0.0410 - q0_75_loss: 0.0336 - q0_95_loss: 0.0133 - val_loss: 0.1595 - val_q0_05_loss: 0.0151 - val_q0_25_loss: 0.0351 - val_q0_5_loss: 0.0414 - val_q0_75_loss: 0.0344 - val_q0_95_loss: 0.0139\n",
      "Epoch 110/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1566 - q0_05_loss: 0.0147 - q0_25_loss: 0.0345 - q0_5_loss: 0.0408 - q0_75_loss: 0.0335 - q0_95_loss: 0.0133 - val_loss: 0.1660 - val_q0_05_loss: 0.0169 - val_q0_25_loss: 0.0374 - val_q0_5_loss: 0.0435 - val_q0_75_loss: 0.0348 - val_q0_95_loss: 0.0137\n",
      "Epoch 111/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1570 - q0_05_loss: 0.0148 - q0_25_loss: 0.0347 - q0_5_loss: 0.0409 - q0_75_loss: 0.0336 - q0_95_loss: 0.0134 - val_loss: 0.1575 - val_q0_05_loss: 0.0146 - val_q0_25_loss: 0.0342 - val_q0_5_loss: 0.0414 - val_q0_75_loss: 0.0341 - val_q0_95_loss: 0.0135\n",
      "Epoch 112/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1557 - q0_05_loss: 0.0147 - q0_25_loss: 0.0345 - q0_5_loss: 0.0406 - q0_75_loss: 0.0332 - q0_95_loss: 0.0131 - val_loss: 0.1683 - val_q0_05_loss: 0.0162 - val_q0_25_loss: 0.0381 - val_q0_5_loss: 0.0447 - val_q0_75_loss: 0.0359 - val_q0_95_loss: 0.0138\n",
      "Epoch 113/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1570 - q0_05_loss: 0.0148 - q0_25_loss: 0.0347 - q0_5_loss: 0.0410 - q0_75_loss: 0.0336 - q0_95_loss: 0.0132 - val_loss: 0.1625 - val_q0_05_loss: 0.0168 - val_q0_25_loss: 0.0372 - val_q0_5_loss: 0.0423 - val_q0_75_loss: 0.0336 - val_q0_95_loss: 0.0130\n",
      "Epoch 114/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1573 - q0_05_loss: 0.0149 - q0_25_loss: 0.0348 - q0_5_loss: 0.0410 - q0_75_loss: 0.0336 - q0_95_loss: 0.0133 - val_loss: 0.1587 - val_q0_05_loss: 0.0148 - val_q0_25_loss: 0.0356 - val_q0_5_loss: 0.0415 - val_q0_75_loss: 0.0337 - val_q0_95_loss: 0.0133\n",
      "Epoch 115/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1570 - q0_05_loss: 0.0147 - q0_25_loss: 0.0346 - q0_5_loss: 0.0410 - q0_75_loss: 0.0337 - q0_95_loss: 0.0133 - val_loss: 0.1609 - val_q0_05_loss: 0.0157 - val_q0_25_loss: 0.0356 - val_q0_5_loss: 0.0422 - val_q0_75_loss: 0.0343 - val_q0_95_loss: 0.0135\n",
      "Epoch 116/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1573 - q0_05_loss: 0.0149 - q0_25_loss: 0.0349 - q0_5_loss: 0.0410 - q0_75_loss: 0.0335 - q0_95_loss: 0.0133 - val_loss: 0.1574 - val_q0_05_loss: 0.0142 - val_q0_25_loss: 0.0339 - val_q0_5_loss: 0.0408 - val_q0_75_loss: 0.0345 - val_q0_95_loss: 0.0143\n",
      "Epoch 117/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1575 - q0_05_loss: 0.0148 - q0_25_loss: 0.0347 - q0_5_loss: 0.0410 - q0_75_loss: 0.0337 - q0_95_loss: 0.0135 - val_loss: 0.1548 - val_q0_05_loss: 0.0145 - val_q0_25_loss: 0.0345 - val_q0_5_loss: 0.0404 - val_q0_75_loss: 0.0329 - val_q0_95_loss: 0.0127\n",
      "Epoch 118/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1567 - q0_05_loss: 0.0148 - q0_25_loss: 0.0346 - q0_5_loss: 0.0408 - q0_75_loss: 0.0335 - q0_95_loss: 0.0133 - val_loss: 0.1527 - val_q0_05_loss: 0.0140 - val_q0_25_loss: 0.0340 - val_q0_5_loss: 0.0399 - val_q0_75_loss: 0.0325 - val_q0_95_loss: 0.0126\n",
      "Epoch 119/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1561 - q0_05_loss: 0.0147 - q0_25_loss: 0.0344 - q0_5_loss: 0.0407 - q0_75_loss: 0.0333 - q0_95_loss: 0.0132 - val_loss: 0.1616 - val_q0_05_loss: 0.0163 - val_q0_25_loss: 0.0369 - val_q0_5_loss: 0.0422 - val_q0_75_loss: 0.0334 - val_q0_95_loss: 0.0130\n",
      "Epoch 120/300\n",
      "3656/3656 [==============================] - 18s 5ms/step - loss: 0.1564 - q0_05_loss: 0.0147 - q0_25_loss: 0.0345 - q0_5_loss: 0.0408 - q0_75_loss: 0.0335 - q0_95_loss: 0.0132 - val_loss: 0.1570 - val_q0_05_loss: 0.0154 - val_q0_25_loss: 0.0354 - val_q0_5_loss: 0.0410 - val_q0_75_loss: 0.0327 - val_q0_95_loss: 0.0128\n",
      "[Rep 01] eval chunk 50/1463\n",
      "[Rep 01] eval chunk 100/1463\n",
      "[Rep 01] eval chunk 150/1463\n",
      "[Rep 01] eval chunk 200/1463\n",
      "[Rep 01] eval chunk 250/1463\n",
      "[Rep 01] eval chunk 300/1463\n",
      "[Rep 01] eval chunk 350/1463\n",
      "[Rep 01] eval chunk 400/1463\n",
      "[Rep 01] eval chunk 450/1463\n",
      "[Rep 01] eval chunk 500/1463\n",
      "[Rep 01] eval chunk 550/1463\n",
      "[Rep 01] eval chunk 600/1463\n",
      "[Rep 01] eval chunk 650/1463\n",
      "[Rep 01] eval chunk 700/1463\n",
      "[Rep 01] eval chunk 750/1463\n",
      "[Rep 01] eval chunk 800/1463\n",
      "[Rep 01] eval chunk 850/1463\n",
      "[Rep 01] eval chunk 900/1463\n",
      "[Rep 01] eval chunk 950/1463\n",
      "[Rep 01] eval chunk 1000/1463\n",
      "[Rep 01] eval chunk 1050/1463\n",
      "[Rep 01] eval chunk 1100/1463\n",
      "[Rep 01] eval chunk 1150/1463\n",
      "[Rep 01] eval chunk 1200/1463\n",
      "[Rep 01] eval chunk 1250/1463\n",
      "[Rep 01] eval chunk 1300/1463\n",
      "[Rep 01] eval chunk 1350/1463\n",
      "[Rep 01] eval chunk 1400/1463\n",
      "[Rep 01] eval chunk 1450/1463\n",
      "[Rep 01/1] Crossing rate = 0.000000\n",
      "\n",
      "=== Summary over repetitions (fixed split, retrain only) ===\n",
      "Crossing rate mean = 0.000000\n",
      "Crossing rate SD   = NA\n",
      "CRPS_z   mean = 0.055668 | SD = NA\n",
      "CRPS_raw mean = 1.053670 | SD = NA\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "os.environ[\"TF_ENABLE_ONEDNN_OPTS\"] = \"0\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "import gc\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "\n",
    "BASE_SEED = 2024\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(BASE_SEED)\n",
    "\n",
    "DATA_DIR = Path(\"/home/wangxc1117/surface_air_temperature/data2024\")\n",
    "\n",
    "OBS_RATIO = 0.10\n",
    "VAL_STATION_RATIO = 0.10\n",
    "\n",
    "T_KEEP = 100\n",
    "N_FILES = 5\n",
    "\n",
    "GRID_SIZES = (5, 9, 12)\n",
    "H_LIST = (10, 15, 45)\n",
    "\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 512\n",
    "LR = 1e-3\n",
    "PATIENCE = 30\n",
    "\n",
    "TAUS = [0.05, 0.25, 0.5, 0.75, 0.95]\n",
    "\n",
    "N_REP = 1\n",
    "SEED_OFFSET = 1000\n",
    "\n",
    "STATIONS_PER_CHUNK = 128\n",
    "\n",
    "\n",
    "tf.get_logger().setLevel(\"ERROR\")\n",
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "print(\"GPUs:\", gpus)\n",
    "\n",
    "\n",
    "ENGINES = [\"netcdf4\", \"h5netcdf\", \"scipy\"]\n",
    "def open_dataset_robust(path: Path):\n",
    "    last_err = None\n",
    "    for eng in ENGINES:\n",
    "        try:\n",
    "            return xr.open_dataset(str(path), engine=eng, decode_cf=True, mask_and_scale=True)\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "    raise RuntimeError(f\"Failed: {path.name} -> {last_err}\")\n",
    "\n",
    "\n",
    "def pick_last_n_files(data_dir: Path, n_files: int):\n",
    "    files = sorted([p for p in data_dir.iterdir() if p.is_file()])\n",
    "    if len(files) == 0:\n",
    "        raise RuntimeError(f\"No files in {data_dir}\")\n",
    "    if len(files) < n_files:\n",
    "        return files\n",
    "    return files[-n_files:]\n",
    "\n",
    "\n",
    "def wendland_c2_vec(d):\n",
    "    out = np.zeros_like(d, dtype=np.float32)\n",
    "    m = (d >= 0.0) & (d <= 1.0)\n",
    "    dm = d[m]\n",
    "    out[m] = ((1.0 - dm) ** 6) * (35.0 * dm**2 + 18.0 * dm + 3.0) / 3.0\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_space_basis_fast(s_xy, grid_sizes=GRID_SIZES, theta_scale=2.5, chunk=8192):\n",
    "    n = s_xy.shape[0]\n",
    "    out_cols = []\n",
    "\n",
    "    for g in grid_sizes:\n",
    "        knots_1d = np.linspace(0.0, 1.0, g, dtype=np.float32)\n",
    "        kx, ky = np.meshgrid(knots_1d, knots_1d)\n",
    "        knots = np.column_stack([kx.ravel(), ky.ravel()]).astype(np.float32)\n",
    "        K = knots.shape[0]\n",
    "\n",
    "        spacing = 1.0 / (g - 1)\n",
    "        theta = theta_scale * spacing\n",
    "\n",
    "        phi = np.empty((n, K), dtype=np.float32)\n",
    "\n",
    "        for a in range(0, n, chunk):\n",
    "            b = min(a + chunk, n)\n",
    "            X = s_xy[a:b]\n",
    "            dx = X[:, 0:1] - knots[None, :, 0]\n",
    "            dy = X[:, 1:2] - knots[None, :, 1]\n",
    "            dist = np.sqrt(dx * dx + dy * dy) / (theta + 1e-12)\n",
    "            phi[a:b] = wendland_c2_vec(dist)\n",
    "\n",
    "        out_cols.append(phi)\n",
    "\n",
    "    return np.concatenate(out_cols, axis=1)\n",
    "\n",
    "\n",
    "def build_time_basis(t_norm, H_list=H_LIST):\n",
    "    cols = []\n",
    "    for H in H_list:\n",
    "        knots = np.linspace(0.0, 1.0, H, dtype=np.float32)\n",
    "        kappa = abs(knots[1] - knots[0]) if H >= 2 else 1.0\n",
    "        diff = (t_norm[:, None] - knots[None, :]) / (kappa + 1e-12)\n",
    "        cols.append(np.exp(-0.5 * diff**2).astype(np.float32))\n",
    "    return np.concatenate(cols, axis=1)\n",
    "\n",
    "\n",
    "def tilted_loss(tau):\n",
    "    tau = float(tau)\n",
    "    def loss(y_true, y_pred):\n",
    "        e = y_true - y_pred\n",
    "        return tf.reduce_mean(tf.maximum(tau * e, (tau - 1.0) * e))\n",
    "    return loss\n",
    "\n",
    "\n",
    "def build_model_multi_quantile(input_dim):\n",
    "    reg = regularizers.L1L2(l1=1e-5, l2=1e-4)\n",
    "\n",
    "    inp = keras.Input(shape=(input_dim,), name=\"X\")\n",
    "    x = Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\", kernel_regularizer=reg)(inp)\n",
    "    x = Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\", kernel_regularizer=reg)(x)\n",
    "\n",
    "    for _ in range(6):\n",
    "        x = Dense(100, activation=\"relu\", kernel_initializer=\"random_normal\")(x)\n",
    "\n",
    "    x = Dense(50, activation=\"relu\", kernel_initializer=\"random_normal\")(x)\n",
    "    x = Dense(50, activation=\"relu\", kernel_initializer=\"random_normal\")(x)\n",
    "\n",
    "    outputs = {}\n",
    "    losses = {}\n",
    "    for tau in TAUS:\n",
    "        name = f\"q{str(tau).replace('.','_')}\"\n",
    "        outputs[name] = Dense(1, kernel_initializer=\"random_normal\", name=name)(x)\n",
    "        losses[name] = tilted_loss(tau)\n",
    "\n",
    "    model = keras.Model(inputs=inp, outputs=outputs, name=\"STDK_MultiQuantile\")\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=LR), loss=losses)\n",
    "    return model\n",
    "\n",
    "\n",
    "def crps_from_quantiles_weighted(y_true, preds_dict, taus=TAUS):\n",
    "    y = np.asarray(y_true).reshape(-1).astype(np.float64)\n",
    "\n",
    "    taus = np.asarray(taus, dtype=np.float64)\n",
    "    taus = np.sort(taus)\n",
    "\n",
    "    w = np.zeros_like(taus)\n",
    "    w[0] = 0.5 * (taus[1] - taus[0])\n",
    "    w[-1] = 0.5 * (taus[-1] - taus[-2])\n",
    "    w[1:-1] = 0.5 * (taus[2:] - taus[:-2])\n",
    "\n",
    "    check_sum = np.zeros_like(y, dtype=np.float64)\n",
    "    for tau, wk in zip(taus, w):\n",
    "        key = f\"q{str(tau).replace('.','_')}\"\n",
    "        q = np.asarray(preds_dict[key]).reshape(-1).astype(np.float64)\n",
    "        e = y - q\n",
    "        check = np.maximum(tau * e, (tau - 1.0) * e)\n",
    "        check_sum += wk * check\n",
    "\n",
    "    return 2.0 * check_sum\n",
    "\n",
    "\n",
    "def crossing_rate_from_preds(preds_dict, taus=TAUS):\n",
    "    taus = np.asarray(sorted(taus), dtype=np.float64)\n",
    "    keys = [f\"q{str(t).replace('.','_')}\" for t in taus]\n",
    "    Q = np.concatenate([np.asarray(preds_dict[k]).reshape(-1, 1).astype(np.float64) for k in keys], axis=1)\n",
    "    dQ = np.diff(Q, axis=1)\n",
    "    mono = np.all(dQ >= 0.0, axis=1)\n",
    "    return float(1.0 - np.mean(mono))\n",
    "\n",
    "\n",
    "def build_Xy_stationchunk_vectorized(station_ids, Yz, phi_space, phi_time, Ds, D, T):\n",
    "    station_ids = np.asarray(station_ids, dtype=np.int64)\n",
    "    n_st = station_ids.shape[0]\n",
    "\n",
    "    space_part = phi_space[station_ids].astype(np.float32)\n",
    "    y_chunk = Yz[station_ids].astype(np.float32)\n",
    "\n",
    "    X_space = np.repeat(space_part[:, None, :], T, axis=1)\n",
    "    X_time = np.repeat(phi_time[None, :, :].astype(np.float32), n_st, axis=0)\n",
    "\n",
    "    X = np.concatenate([X_space, X_time], axis=2).reshape(n_st * T, D).astype(np.float32)\n",
    "    y = y_chunk.reshape(-1).astype(np.float32)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def make_stream_dataset(station_ids, Yz, phi_space, phi_time, Ds, D, T, batch_size, stations_per_chunk, taus, shuffle, seed):\n",
    "    station_ids = np.asarray(station_ids, dtype=np.int64)\n",
    "    n_st = len(station_ids)\n",
    "\n",
    "    def gen():\n",
    "        rng = np.random.RandomState(seed)\n",
    "        while True:\n",
    "            if shuffle:\n",
    "                order = rng.permutation(n_st)\n",
    "            else:\n",
    "                order = np.arange(n_st, dtype=np.int64)\n",
    "\n",
    "            for a in range(0, n_st, stations_per_chunk):\n",
    "                b = min(a + stations_per_chunk, n_st)\n",
    "                chunk_ids = station_ids[order[a:b]]\n",
    "\n",
    "                Xc, yc = build_Xy_stationchunk_vectorized(chunk_ids, Yz, phi_space, phi_time, Ds, D, T)\n",
    "\n",
    "                n_rows = Xc.shape[0]\n",
    "                for r0 in range(0, n_rows, batch_size):\n",
    "                    r1 = min(r0 + batch_size, n_rows)\n",
    "                    Xb = Xc[r0:r1]\n",
    "                    yb = yc[r0:r1]\n",
    "                    y_dict = {f\"q{str(t).replace('.','_')}\": yb for t in taus}\n",
    "                    yield Xb, y_dict\n",
    "\n",
    "    output_signature = (\n",
    "        tf.TensorSpec(shape=(None, D), dtype=tf.float32),\n",
    "        {f\"q{str(t).replace('.','_')}\": tf.TensorSpec(shape=(None,), dtype=tf.float32) for t in taus}\n",
    "    )\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(gen, output_signature=output_signature)\n",
    "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "\n",
    "files = pick_last_n_files(DATA_DIR, N_FILES)\n",
    "print(\"[FILES] using last:\", len(files))\n",
    "print(\"first:\", files[0].name)\n",
    "print(\"last :\", files[-1].name)\n",
    "\n",
    "ds0 = open_dataset_robust(files[0])\n",
    "lat = ds0[\"lat\"].values.astype(np.float32)\n",
    "lon = ds0[\"lon\"].values.astype(np.float32)\n",
    "n_lat, n_lon = len(lat), len(lon)\n",
    "S = n_lat * n_lon\n",
    "n_time_per_file = int(ds0.sizes[\"time\"])\n",
    "ds0.close()\n",
    "\n",
    "blocks = []\n",
    "time_blocks = []\n",
    "for p in files:\n",
    "    ds = open_dataset_robust(p)\n",
    "    blocks.append(ds[\"TLML\"].values.astype(np.float32).reshape(n_time_per_file, S))\n",
    "    time_blocks.append(pd.to_datetime(ds[\"time\"].values))\n",
    "    ds.close()\n",
    "\n",
    "Y_5days = np.concatenate(blocks, axis=0)\n",
    "t_5days = np.concatenate(time_blocks, axis=0)\n",
    "\n",
    "if Y_5days.shape[0] < T_KEEP:\n",
    "    raise ValueError(f\"Total steps={Y_5days.shape[0]} < T_KEEP={T_KEEP}\")\n",
    "\n",
    "Y_last = Y_5days[-T_KEEP:, :]\n",
    "t_last = t_5days[-T_KEEP:]\n",
    "Y = Y_last.T.astype(np.float32)\n",
    "T = Y.shape[1]\n",
    "\n",
    "print(\"Y (S,T_KEEP):\", Y.shape)\n",
    "print(\"t_last range:\", t_last[0], \"->\", t_last[-1])\n",
    "\n",
    "\n",
    "lat_grid, lon_grid = np.meshgrid(lat, lon, indexing=\"ij\")\n",
    "lat_pts = lat_grid.reshape(-1).astype(np.float32)\n",
    "lon_pts = lon_grid.reshape(-1).astype(np.float32)\n",
    "\n",
    "lat_n = (lat_pts - float(lat_pts.min())) / (float(lat_pts.max() - lat_pts.min()) + 1e-12)\n",
    "lon_n = (lon_pts - float(lon_pts.min())) / (float(lon_pts.max() - lon_pts.min()) + 1e-12)\n",
    "s_xy = np.column_stack([lat_n, lon_n]).astype(np.float32)\n",
    "\n",
    "t_idx = np.arange(T, dtype=np.float32)\n",
    "t_norm = (t_idx - t_idx.min()) / (t_idx.max() - t_idx.min() + 1e-12)\n",
    "\n",
    "phi_space_full = build_space_basis_fast(s_xy)\n",
    "phi_time_full = build_time_basis(t_norm)\n",
    "\n",
    "space_keep = (phi_space_full != 0).any(axis=0)\n",
    "time_keep = (phi_time_full != 0).any(axis=0)\n",
    "\n",
    "phi_space = phi_space_full[:, space_keep].astype(np.float32)\n",
    "phi_time = phi_time_full[:, time_keep].astype(np.float32)\n",
    "\n",
    "Ds = phi_space.shape[1]\n",
    "Dt = phi_time.shape[1]\n",
    "D = Ds + Dt\n",
    "\n",
    "print(\"Ds:\", Ds, \"Dt:\", Dt, \"D:\", D)\n",
    "\n",
    "\n",
    "split_rs = np.random.RandomState(BASE_SEED)\n",
    "n_obs = int(np.round(OBS_RATIO * S))\n",
    "obs_sites = np.sort(split_rs.choice(S, size=n_obs, replace=False))\n",
    "\n",
    "is_obs = np.zeros(S, dtype=bool)\n",
    "is_obs[obs_sites] = True\n",
    "miss_sites = np.where(~is_obs)[0]\n",
    "\n",
    "n_val = max(1, int(np.round(VAL_STATION_RATIO * n_obs)))\n",
    "perm = split_rs.permutation(n_obs)\n",
    "val_sites = np.sort(obs_sites[perm[:n_val]])\n",
    "train_sites = np.sort(obs_sites[perm[n_val:]])\n",
    "\n",
    "y_train_raw = Y[train_sites].reshape(-1).astype(np.float32)\n",
    "y_mu = float(np.mean(y_train_raw))\n",
    "y_sd = float(np.std(y_train_raw) + 1e-12)\n",
    "Yz = (Y - y_mu) / y_sd\n",
    "\n",
    "print(\"Stations:\", \"train\", len(train_sites), \"| val\", len(val_sites), \"| miss\", len(miss_sites))\n",
    "\n",
    "\n",
    "train_rows = int(len(train_sites) * T)\n",
    "val_rows = int(len(val_sites) * T)\n",
    "steps_per_epoch = int(np.ceil(train_rows / BATCH_SIZE))\n",
    "val_steps = int(np.ceil(val_rows / BATCH_SIZE))\n",
    "print(\"train rows:\", train_rows, \"| val rows:\", val_rows)\n",
    "print(\"steps/epoch:\", steps_per_epoch, \"| val_steps:\", val_steps)\n",
    "\n",
    "\n",
    "n_chunks_miss = int(np.ceil(len(miss_sites) / STATIONS_PER_CHUNK))\n",
    "\n",
    "cross_list = []\n",
    "crps_z_list = []\n",
    "crps_raw_list = []\n",
    "\n",
    "for rep in range(1, N_REP + 1):\n",
    "    rep_seed = BASE_SEED + SEED_OFFSET + rep\n",
    "\n",
    "    random.seed(rep_seed)\n",
    "    np.random.seed(rep_seed)\n",
    "    tf.random.set_seed(rep_seed)\n",
    "\n",
    "    keras.backend.clear_session()\n",
    "\n",
    "    train_ds = make_stream_dataset(\n",
    "        station_ids=train_sites,\n",
    "        Yz=Yz,\n",
    "        phi_space=phi_space,\n",
    "        phi_time=phi_time,\n",
    "        Ds=Ds,\n",
    "        D=D,\n",
    "        T=T,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        stations_per_chunk=STATIONS_PER_CHUNK,\n",
    "        taus=TAUS,\n",
    "        shuffle=True,\n",
    "        seed=rep_seed + 11,\n",
    "    )\n",
    "\n",
    "    val_ds = make_stream_dataset(\n",
    "        station_ids=val_sites,\n",
    "        Yz=Yz,\n",
    "        phi_space=phi_space,\n",
    "        phi_time=phi_time,\n",
    "        Ds=Ds,\n",
    "        D=D,\n",
    "        T=T,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        stations_per_chunk=STATIONS_PER_CHUNK,\n",
    "        taus=TAUS,\n",
    "        shuffle=False,\n",
    "        seed=rep_seed + 17,\n",
    "    )\n",
    "\n",
    "    model = build_model_multi_quantile(D)\n",
    "\n",
    "    model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=val_ds,\n",
    "        validation_steps=val_steps,\n",
    "        verbose=1,\n",
    "        callbacks=[\n",
    "            keras.callbacks.EarlyStopping(\n",
    "                monitor=\"val_loss\",\n",
    "                patience=PATIENCE,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    sum_crps_z = 0.0\n",
    "    sum_crps_raw = 0.0\n",
    "    sum_cross = 0.0\n",
    "    count = 0\n",
    "\n",
    "    for ci in range(n_chunks_miss):\n",
    "        a = ci * STATIONS_PER_CHUNK\n",
    "        b = min((ci + 1) * STATIONS_PER_CHUNK, len(miss_sites))\n",
    "        chunk_sites = miss_sites[a:b]\n",
    "\n",
    "        X_chunk, y_true_z = build_Xy_stationchunk_vectorized(chunk_sites, Yz, phi_space, phi_time, Ds, D, T)\n",
    "        preds_z = model.predict(X_chunk, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "        crps_vec_z = crps_from_quantiles_weighted(y_true_z, preds_z, taus=TAUS)\n",
    "        sum_crps_z += float(np.sum(crps_vec_z))\n",
    "\n",
    "        y_true_raw = (y_true_z.astype(np.float64) * y_sd + y_mu)\n",
    "        preds_raw = {}\n",
    "        for tau in TAUS:\n",
    "            k = f\"q{str(tau).replace('.','_')}\"\n",
    "            preds_raw[k] = (np.asarray(preds_z[k]).reshape(-1).astype(np.float64) * y_sd + y_mu)\n",
    "\n",
    "        crps_vec_raw = crps_from_quantiles_weighted(y_true_raw, preds_raw, taus=TAUS)\n",
    "        sum_crps_raw += float(np.sum(crps_vec_raw))\n",
    "\n",
    "        sum_cross += crossing_rate_from_preds(preds_z, taus=TAUS) * float(y_true_z.size)\n",
    "        count += int(y_true_z.size)\n",
    "\n",
    "        del X_chunk\n",
    "        gc.collect()\n",
    "\n",
    "        if (ci + 1) % 50 == 0:\n",
    "            print(f\"[Rep {rep:02d}] eval chunk {ci+1}/{n_chunks_miss}\")\n",
    "\n",
    "    cross_list.append(sum_cross / count)\n",
    "    crps_z_list.append(sum_crps_z / count)\n",
    "    crps_raw_list.append(sum_crps_raw / count)\n",
    "\n",
    "    print(f\"[Rep {rep:02d}/{N_REP}] Crossing rate = {cross_list[-1]:.6f}\")\n",
    "\n",
    "    del model\n",
    "    gc.collect()\n",
    "\n",
    "cross_arr = np.asarray(cross_list, dtype=np.float64)\n",
    "crps_z_arr = np.asarray(crps_z_list, dtype=np.float64)\n",
    "crps_raw_arr = np.asarray(crps_raw_list, dtype=np.float64)\n",
    "\n",
    "print(\"\\n=== Summary over repetitions (fixed split, retrain only) ===\")\n",
    "print(f\"Crossing rate mean = {float(np.mean(cross_arr)):.6f}\")\n",
    "print(f\"Crossing rate SD   = {float(np.std(cross_arr, ddof=1)):.6f}\" if N_REP > 1 else \"Crossing rate SD   = NA\")\n",
    "print(f\"CRPS_z   mean = {float(np.mean(crps_z_arr)):.6f} | SD = {float(np.std(crps_z_arr, ddof=1)):.6f}\" if N_REP > 1 else f\"CRPS_z   mean = {float(np.mean(crps_z_arr)):.6f} | SD = NA\")\n",
    "print(f\"CRPS_raw mean = {float(np.mean(crps_raw_arr)):.6f} | SD = {float(np.std(crps_raw_arr, ddof=1)):.6f}\" if N_REP > 1 else f\"CRPS_raw mean = {float(np.mean(crps_raw_arr)):.6f} | SD = NA\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepKriging.env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
